import os
import sqlite3
from datetime import datetime
from typing import Tuple

import cv2
from ultralytics import YOLO

# =========================
# CONFIG / CONSTANTS
# =========================
LOG_DIR = "logs"
SNAPSHOT_DIR = "outputs/snapshots"
MODEL_PATH = "yolov8n.pt"

# Flip mode:
#   None -> no flip
#   0    -> vertical (upside-down)
#   1    -> horizontal (mirror) (most common)
#  -1    -> both axes
CAMERA_FLIP_MODE = 1

os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(SNAPSHOT_DIR, exist_ok=True)


# =========================
# HELPERS
# =========================
def load_model(model_path: str, target_class_name: str = "dog") -> Tuple[YOLO, int]:
    """Load YOLO model and return (model, target_class_id)."""
    model = YOLO(model_path)

    class_id = None
    for idx, name in model.names.items():
        if name == target_class_name:
            class_id = idx
            break

    if class_id is None:
        raise ValueError(
            f"'{target_class_name}' not found in model.names: {model.names}"
        )

    print(
        f"[INFO] Using model '{model_path}' with '{target_class_name}' class id = {class_id}"
    )
    return model, class_id


def init_db(path: str):
    """Initialize SQLite DB and return (conn, cursor)."""
    conn = sqlite3.connect(path, check_same_thread=False)
    c = conn.cursor()
    c.execute(
        """
        CREATE TABLE IF NOT EXISTS logs (
            timestamp TEXT,
            speed REAL,
            snapshot_path TEXT
        )
        """
    )
    conn.commit()
    return conn, c


def normalize_frame(frame):
    """Flip frame according to CAMERA_FLIP_MODE (if set)."""
    if CAMERA_FLIP_MODE is None:
        return frame
    return cv2.flip(frame, CAMERA_FLIP_MODE)


# =========================
# MAIN
# =========================
def main():
    # 1) Camera init
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    ret, frame = cap.read()
    if not ret or frame is None:
        print("[ERROR] Could not access camera.")
        cap.release()
        return

    frame = normalize_frame(frame)
    frame_h, frame_w = frame.shape[:2]
    fps = cap.get(cv2.CAP_PROP_FPS) or 30

    # 2) Load model & DB
    model, DOG_CLASS_ID = load_model(MODEL_PATH)
    conn, c = init_db(os.path.join(LOG_DIR, "detections.db"))

    object_tracker = {}  # track_id -> (cx, cy, timestamp)
    snapshot_counter = 0

    print("[INFO] Press Q to exit.")
    print("[INFO] Dog detection ACTIVE (No Zones).")

    try:
        while True:
            ret, frame = cap.read()
            if not ret or frame is None:
                print("[WARN] Empty frame from camera, stopping.")
                break

            frame = normalize_frame(frame)

            # 3) Run YOLO tracking
            results = model.track(
                frame,
                persist=True,
                tracker="bytetrack.yaml",
                classes=[DOG_CLASS_ID],
                conf=0.35,
                verbose=False,
            )

            if results and results[0].boxes is not None:
                annotated_frame = results[0].plot()
            else:
                annotated_frame = frame.copy()

            # 4) Handle detections
            if results and results[0].boxes is not None:
                for r in results:
                    if getattr(r.boxes, "id", None) is None:
                        continue

                    for box, cls_id, track_id in zip(
                        r.boxes.xyxy, r.boxes.cls, r.boxes.id
                    ):
                        if int(cls_id) != DOG_CLASS_ID:
                            continue

                        x1, y1, x2, y2 = map(int, box)
                        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

                        # normalize track_id extraction across versions
                        try:
                            track_id_val = int(track_id.item())
                        except Exception:
                            track_id_val = int(track_id)

                        now = datetime.now()
                        now_str = now.strftime("%Y-%m-%d %H:%M:%S")

                        # Speed estimation
                        speed = 0.0
                        if track_id_val in object_tracker:
                            prev_cx, prev_cy, prev_time = object_tracker[track_id_val]
                            dist = ((cx - prev_cx) ** 2 + (cy - prev_cy) ** 2) ** 0.5
                            time_elapsed = (now - prev_time).total_seconds() or 1e-6
                            speed = (dist / time_elapsed) * (fps / 100.0)

                        object_tracker[track_id_val] = (cx, cy, now)

                        # Snapshot
                        snapshot_counter += 1
                        snap_name = f"dog_{snapshot_counter}.jpg"
                        snap_path = os.path.join(SNAPSHOT_DIR, snap_name)

                        # safe crop bounds
                        h, w = frame.shape[:2]
                        y1c, y2c = max(0, min(y1, h - 1)), max(0, min(y2, h - 1))
                        x1c, x2c = max(0, min(x1, w - 1)), max(0, min(x2, w - 1))

                        cropped = frame[y1c:y2c, x1c:x2c]
                        if cropped is not None and cropped.size > 0:
                            cv2.imwrite(snap_path, cropped)
                        else:
                            # fallback: save annotated frame
                            cv2.imwrite(snap_path, annotated_frame)

                        # Log to DB
                        c.execute(
                            "INSERT INTO logs (timestamp, speed, snapshot_path) VALUES (?, ?, ?)",
                            (now_str, round(speed, 2), snap_path),
                        )
                        conn.commit()

                        print(
                            f"[INFO] Dog detected | Speed={round(speed,2)} | Snapshot saved: {snap_path}"
                        )

            # 5) Display
            cv2.imshow("Dog Detection (No Zones)", annotated_frame)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break

    finally:
        cap.release()
        cv2.destroyAllWindows()
        conn.close()
        print("[INFO] Shutdown complete.")


if __name__ == "__main__":
    main()
